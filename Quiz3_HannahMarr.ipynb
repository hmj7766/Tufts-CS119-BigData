{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5883899-60c2-40f1-9ba4-a34030aa9833",
   "metadata": {},
   "source": [
    "## TrafficRank [50 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7f181-fe26-4b5d-8490-72dd8788adb7",
   "metadata": {},
   "source": [
    "Primary Author: Hannah Marr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb9d90-3fa2-41dd-b49e-cac1bc7af51d",
   "metadata": {},
   "source": [
    "## Viewing Chicago Taxi Rides [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15352032-c78f-41a5-b6b6-a783f3e2a98d",
   "metadata": {},
   "source": [
    "The city is divided into 77 “community areas,” thus giving us a 77 × 77 matrix of T entries where Tij is the number of trips from community area i to community area j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45df375-ccb6-42ea-9cde-0bafee5cb2ec",
   "metadata": {},
   "source": [
    "[15 points] The given data has rows (i, j, Tij), sometimes known as Coordinate format. It is supported by many libraries, SciPy.sparse.coo_matrix among them. Since the matrix is just 77 × 77, a “big data” technique is not required here. Read the data as a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9123f70-44f9-4262-9784-f398d548642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/singhj/big-data-repo/main/datasets/chicago-taxi-rides.csv > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1124809a-61d2-4b4a-9b39-6fe5f59e382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy is a Python library that will allow us to work with matrices much more easily, and pandas, which will allow us to read the csv file more easily\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c353680b-4f6b-4fae-a831-b120f83f18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will load the dataset\n",
    "url = \"https://raw.githubusercontent.com/singhj/big-data-repo/main/datasets/chicago-taxi-rides.csv\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a4ee851-171c-4672-bcf5-388046264310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will initialize a 77x77 matrix of zeros\n",
    "matrix_size = 77\n",
    "taxi_matrix = np.zeros((matrix_size, matrix_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f19bd42-d26e-4f89-81f5-089b3fb15396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We should clean the data of any null values (missing data)\n",
    "cleaned_data = data.dropna(subset=['pickup_community_area', 'dropoff_community_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5744fcf5-fc2b-43d9-9304-d333a7dd2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We populate the matrix with the cleaned data\n",
    "for _, row in cleaned_data.iterrows():\n",
    "  pickup = int(row['pickup_community_area']) - 1  #Converting to 0-based index\n",
    "  dropoff = int(row['dropoff_community_area']) - 1  #Converting to 0-based index\n",
    "  taxi_matrix[pickup, dropoff] = row['trips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "319320b3-c97e-4713-9537-2f6a5d6adbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row index in the taxi_matrix\n",
    "for i in range(77):\n",
    "    # Calculate the sum of the elements in the current row\n",
    "  row_sum = np.sum(taxi_matrix[i])\n",
    "    # Check if the row sum is greater than 0 to avoid division by zero\n",
    "  if row_sum > 0:\n",
    "      # Normalize the current row by dividing each element by the row sum\n",
    "    taxi_matrix[i] /= row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaedb0fb-cb08-45ed-b219-8da5b2d4ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the matrix to a dataframe for easier viewing\n",
    "taxi_matrix_df = pd.DataFrame(taxi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b512f05-8d69-40be-9384-5d53caf93c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.314364  0.115114  0.071644  0.024641  0.009505  0.066561  0.023222   \n",
      "1  0.082866  0.499626  0.038258  0.052161  0.010238  0.026304  0.012240   \n",
      "2  0.025775  0.013679  0.234461  0.039468  0.023663  0.194869  0.052170   \n",
      "3  0.020971  0.061731  0.092477  0.215333  0.046365  0.103901  0.037329   \n",
      "4  0.008201  0.009023  0.053918  0.047155  0.132817  0.197859  0.075908   \n",
      "5  0.009504  0.003815  0.065692  0.016522  0.031024  0.277002  0.125162   \n",
      "6  0.003997  0.002025  0.019605  0.007028  0.014300  0.158495  0.219527   \n",
      "7  0.002220  0.001202  0.010018  0.003485  0.005290  0.052612  0.065603   \n",
      "8  0.011006  0.014544  0.004324  0.011006  0.007075  0.025157  0.010613   \n",
      "9  0.004620  0.013369  0.005407  0.005024  0.004236  0.010708  0.006983   \n",
      "\n",
      "          7         8         9  \n",
      "0  0.071028  0.000233  0.001127  \n",
      "1  0.034980  0.000268  0.001963  \n",
      "2  0.114765  0.000092  0.000612  \n",
      "3  0.067729  0.000584  0.001670  \n",
      "4  0.102646  0.000350  0.001395  \n",
      "5  0.169481  0.000248  0.000836  \n",
      "6  0.261373  0.000160  0.000523  \n",
      "7  0.367008  0.000091  0.000365  \n",
      "8  0.040487  0.324686  0.141509  \n",
      "9  0.031529  0.013880  0.556532  \n"
     ]
    }
   ],
   "source": [
    "#Displaying the first 10 rows and columns of the matrix\n",
    "print(taxi_matrix_df.iloc[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c3ba4-2b8f-41dd-9b77-1cf4783b0fb1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48439998-4446-45aa-848b-7525ac9a6f8e",
   "metadata": {},
   "source": [
    "[15 points] Using your formulation of the TrafficRank algorithm, calculate the rankings of the Chicago community areas after 0, 1, 2, 3, 4, 5 and 6 iterations of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdc146d0-334d-4ca2-95b7-249cc832aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_rank(taxi_matrix, iterations, d=0.85):\n",
    "  # Get the number of nodes (taxi locations) from the shape of the taxi_matrix\n",
    "  N = taxi_matrix.shape[0]\n",
    "  # Initialize the rank vector R with equal probabilities for each node\n",
    "  R = np.ones(N) / N\n",
    "  # Calculate the teleportation factor to be added in the rank update\n",
    "  teleport = (1 - d) / N * np.ones(N)\n",
    "\n",
    "  # Iterate for the specified number of iterations to update ranks\n",
    "  for _ in range(iterations):\n",
    "    # Update the rank vector R using the TrafficRank formula\n",
    "    R = d * taxi_matrix.T.dot(R) + teleport\n",
    "  # Return the final rank vector\n",
    "  return R\n",
    "\n",
    "# List of iterations to calculate ranks for\n",
    "iterations = [0, 1, 2, 3, 4, 5, 6]\n",
    "# Dictionary to store the rank results for each iteration\n",
    "ranks = {}\n",
    "for i in iterations:\n",
    "  # Calculate the traffic rank for the current iteration and store it in the ranks dictionary\n",
    "  ranks[i] = traffic_rank(taxi_matrix, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d499433b-f98d-48d3-ab38-6e26e99e300d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701, 0.01298701, 0.01298701, 0.01298701,\n",
       "        0.01298701, 0.01298701]),\n",
       " 1: array([0.01006411, 0.01404195, 0.017091  , 0.01119958, 0.00891423,\n",
       "        0.02929688, 0.01948441, 0.07359307, 0.0060187 , 0.01223099,\n",
       "        0.00854053, 0.0081056 , 0.00928916, 0.00967701, 0.01267731,\n",
       "        0.01373032, 0.00972559, 0.0058376 , 0.00981422, 0.00549229,\n",
       "        0.01040191, 0.01625237, 0.00800729, 0.02341066, 0.0146667 ,\n",
       "        0.00655273, 0.0079325 , 0.05225152, 0.00722279, 0.00946594,\n",
       "        0.00848623, 0.05911194, 0.01983566, 0.00833922, 0.01217695,\n",
       "        0.00625109, 0.00787284, 0.01030114, 0.00837593, 0.00762709,\n",
       "        0.01972437, 0.01072687, 0.01391116, 0.01506588, 0.00750423,\n",
       "        0.00972182, 0.00545874, 0.00988917, 0.01688801, 0.0082014 ,\n",
       "        0.01097932, 0.00591853, 0.00846745, 0.00746094, 0.0059192 ,\n",
       "        0.03187698, 0.00690816, 0.01051418, 0.01513366, 0.00770525,\n",
       "        0.00965782, 0.00549654, 0.00731733, 0.00995513, 0.00734138,\n",
       "        0.00944536, 0.0094967 , 0.00998031, 0.01163151, 0.00967553,\n",
       "        0.00934564, 0.00695207, 0.0069646 , 0.00749387, 0.00759241,\n",
       "        0.03111607, 0.01319538]),\n",
       " 2: array([0.00940975, 0.01343462, 0.01823984, 0.01088766, 0.00954854,\n",
       "        0.0395703 , 0.02921042, 0.12328668, 0.0040426 , 0.01046308,\n",
       "        0.00665126, 0.00605975, 0.0074148 , 0.00833817, 0.01111034,\n",
       "        0.01268455, 0.0077088 , 0.00390556, 0.00755876, 0.00400825,\n",
       "        0.00913916, 0.0167784 , 0.006312  , 0.02907938, 0.01276922,\n",
       "        0.00451158, 0.00582487, 0.06021024, 0.00534446, 0.00717946,\n",
       "        0.0070723 , 0.09066917, 0.0221293 , 0.00682811, 0.01039579,\n",
       "        0.00441069, 0.00577923, 0.0082602 , 0.00706776, 0.00575469,\n",
       "        0.0174447 , 0.00890841, 0.01189062, 0.01299976, 0.00545553,\n",
       "        0.00737645, 0.00363461, 0.0077929 , 0.01734882, 0.00602933,\n",
       "        0.00878427, 0.00385368, 0.00626446, 0.00516849, 0.00385726,\n",
       "        0.02623821, 0.00475313, 0.00855536, 0.01592301, 0.00599106,\n",
       "        0.00747835, 0.00381646, 0.0051669 , 0.00798274, 0.00520901,\n",
       "        0.00739163, 0.00750018, 0.00800126, 0.00985806, 0.00758226,\n",
       "        0.0073158 , 0.00486982, 0.00502637, 0.00517795, 0.00536742,\n",
       "        0.031307  , 0.01362897]),\n",
       " 3: array([0.00923012, 0.01275645, 0.01898469, 0.01085477, 0.01007976,\n",
       "        0.0458965 , 0.03565014, 0.14907861, 0.00344606, 0.00908804,\n",
       "        0.00578565, 0.00516869, 0.0064809 , 0.00772928, 0.00983953,\n",
       "        0.01187411, 0.00655598, 0.00333189, 0.0064375 , 0.0036031 ,\n",
       "        0.00862367, 0.01737954, 0.00564951, 0.03247404, 0.01091312,\n",
       "        0.00380556, 0.00492477, 0.06468486, 0.00459931, 0.00599467,\n",
       "        0.00652294, 0.10543817, 0.02303722, 0.0061726 , 0.00914026,\n",
       "        0.00381296, 0.00485076, 0.00703872, 0.00627103, 0.00493093,\n",
       "        0.01513533, 0.00763688, 0.01007582, 0.01098128, 0.00458746,\n",
       "        0.00609734, 0.00313211, 0.00653091, 0.01667146, 0.0050072 ,\n",
       "        0.00729994, 0.00322473, 0.00519516, 0.00420361, 0.00322157,\n",
       "        0.02274803, 0.00394873, 0.00732304, 0.01602949, 0.00534702,\n",
       "        0.00628137, 0.00331313, 0.00430541, 0.00676002, 0.00434011,\n",
       "        0.0062153 , 0.00633404, 0.00679397, 0.00844978, 0.00634666,\n",
       "        0.00617369, 0.00406675, 0.00428055, 0.00419785, 0.00442582,\n",
       "        0.03125625, 0.0139258 ]),\n",
       " 4: array([0.00918519, 0.01229566, 0.01950894, 0.01089628, 0.01043005,\n",
       "        0.04967219, 0.03939062, 0.16240853, 0.00325089, 0.00822403,\n",
       "        0.0053716 , 0.00477241, 0.00602243, 0.00744643, 0.00903851,\n",
       "        0.01142022, 0.00592487, 0.00313897, 0.00590481, 0.00345805,\n",
       "        0.00843853, 0.01791124, 0.0053653 , 0.03452891, 0.00966071,\n",
       "        0.00353476, 0.00452793, 0.06701292, 0.00426432, 0.00541546,\n",
       "        0.00629042, 0.11278944, 0.02339401, 0.00584624, 0.00838949,\n",
       "        0.00357485, 0.00440677, 0.00634595, 0.00579006, 0.00451089,\n",
       "        0.01368157, 0.00684833, 0.00887941, 0.00961444, 0.00417752,\n",
       "        0.00543284, 0.00296392, 0.00580535, 0.01573077, 0.00450866,\n",
       "        0.00641829, 0.00302029, 0.00466813, 0.00379045, 0.0030108 ,\n",
       "        0.02098052, 0.00363355, 0.00660999, 0.01584169, 0.00507557,\n",
       "        0.00565311, 0.00312053, 0.00393723, 0.00603452, 0.00396106,\n",
       "        0.0055545 , 0.00566013, 0.00608028, 0.00750969, 0.0056467 ,\n",
       "        0.0055318 , 0.00373235, 0.00394268, 0.00378214, 0.00401372,\n",
       "        0.03124363, 0.01414496]),\n",
       " 5: array([0.00918466, 0.01203081, 0.01986205, 0.01095286, 0.01065395,\n",
       "        0.05188576, 0.04150427, 0.16944027, 0.00318008, 0.00772347,\n",
       "        0.00516854, 0.00459255, 0.00579988, 0.00731796, 0.0085812 ,\n",
       "        0.01119583, 0.00558677, 0.00306447, 0.0056486 , 0.00339751,\n",
       "        0.00838426, 0.01829055, 0.00523594, 0.03574367, 0.00890711,\n",
       "        0.00341954, 0.00434607, 0.06823224, 0.00410206, 0.00513344,\n",
       "        0.00618524, 0.1165657 , 0.02354241, 0.00567329, 0.00796079,\n",
       "        0.00346326, 0.00418149, 0.00595934, 0.00551263, 0.00428223,\n",
       "        0.0128457 , 0.00638589, 0.00816372, 0.0087817 , 0.00396894,\n",
       "        0.00508578, 0.00289446, 0.00539651, 0.01484935, 0.00425687,\n",
       "        0.00592011, 0.00294736, 0.00440148, 0.00360974, 0.00293449,\n",
       "        0.02008133, 0.00350273, 0.00621097, 0.01555642, 0.00494967,\n",
       "        0.00532457, 0.00303451, 0.00376932, 0.00561474, 0.00378484,\n",
       "        0.00518769, 0.00527614, 0.00566629, 0.00693054, 0.00525797,\n",
       "        0.00517158, 0.00358328, 0.00377113, 0.00360449, 0.00382536,\n",
       "        0.03125755, 0.01430401]),\n",
       " 6: array([0.0091984 , 0.01189333, 0.02009188, 0.01100401, 0.01079436,\n",
       "        0.05317576, 0.04269497, 0.17322532, 0.00315148, 0.00744481,\n",
       "        0.00506779, 0.00450953, 0.00569322, 0.00726245, 0.00833298,\n",
       "        0.01109389, 0.00540784, 0.00303205, 0.00552288, 0.00337042,\n",
       "        0.00837695, 0.01853714, 0.00517486, 0.03645117, 0.00847563,\n",
       "        0.00336608, 0.00425942, 0.06888297, 0.00401981, 0.00499377,\n",
       "        0.00613484, 0.11856184, 0.0236074 , 0.00557874, 0.00771933,\n",
       "        0.00340575, 0.00406226, 0.00574433, 0.00535558, 0.00415471,\n",
       "        0.01237596, 0.00612126, 0.00775171, 0.00829452, 0.00385795,\n",
       "        0.00490105, 0.00286086, 0.00516798, 0.01412569, 0.00412539,\n",
       "        0.00564403, 0.00291818, 0.00426218, 0.00352864, 0.00290412,\n",
       "        0.01961314, 0.00344495, 0.0059896 , 0.0152648 , 0.00488686,\n",
       "        0.00515075, 0.00299262, 0.00368826, 0.00537539, 0.00369843,\n",
       "        0.00498512, 0.00505959, 0.00542887, 0.00658765, 0.00504396,\n",
       "        0.00496945, 0.0035126 , 0.00367796, 0.00352754, 0.00373499,\n",
       "        0.03128213, 0.01441586])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b189aa-b483-4be2-a464-90e9c5f67ffb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c5e7b-9977-4d55-80bf-a562f2cd5da4",
   "metadata": {},
   "source": [
    "[15 points] An alternate measure of economic rank of an area might be the inverse of a “hardship index,” defined and quantified here. How well, or poorly, do your calculations of TrafficRank for Chicago community areas correspond with the inverse of hardship index? Give a qualitative analysis in plain English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c1677-97c1-4cc4-828d-9de772570289",
   "metadata": {},
   "source": [
    "At first glance, the TrafficRank algorithm for Chicago community areas may appear to correspond with the inverse of a hardship index. For example, community area 8, Near North Side, which has one of the lowest hardship index scores (8), has the highest TrafficRank score after 6 iterations (0.17322532), indicating a lot of traffic is directed there. The Loop community area (32) also has a very low hardship index score (9), and one of the highest TrafficRank scores after 6 iterations (0.11856184). However, Lakeview (community area 6), with another low hardship index score of 9.9, has a TrafficRank score of 0.05317576 after 6 iterations, which is lower than Near West Side's (community area 28) traffic rank score of 0.06888297, although this community area has a much higher hardship index score of 26.6. As we can see, the TrafficRank algorithm corresponds with the inverse of a hardship index for some, but not all, community areas. This algorithm can be used to guide our understanding, but should not be used to definitively qualify the inverse of a hardship index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcacda-85c0-4842-af86-23a40c82e086",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748a74a-7096-49e3-b8ca-729637c22c74",
   "metadata": {},
   "source": [
    "## Text Processing [50 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bcc43-9f0e-417f-aa7b-c6814a16b0f9",
   "metadata": {},
   "source": [
    "About TF-IDF [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02d5ab-9e75-4109-8757-635b221f3843",
   "metadata": {},
   "source": [
    "[4 points] We can calculate TF values of each word in a given document. Explain why the calculation of IDF can only apply to a corpus, not to a specific document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799b238-ca9c-4708-bb14-47175cb7f8ce",
   "metadata": {},
   "source": [
    "The calculation of IDF can only apply to a corpus for a few primary reasons. Firstly, IDF is based on the frequency of a word across multiple documents. If a word appears in many documents, it is seen as less significant, since the information it provides is not unique. However, if the word appears in only a few documents, it is deemed important. This comparison requires multiple documents to determine the rarity of a word.\n",
    "\n",
    "Additionally, the N in the formulat used to calculate the IDF is the total number of documents in the corpus, and df(t) is the number of documents containing the term t. Without a corpus to examine, df(t) cannot be defined, which renders IDF meaningless when used for a single document\n",
    "\n",
    "Finally, IDF is used to weigh terms based on their relevance and rarity in multiple documents. In a single document, all terms within are inherently relevant to that document, which makes the IDF calculation unnecessary and uninformative.\n",
    "\n",
    "IDF requires the broader context of a corpus to effectively evaluate the importance of different words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698a675-6c46-4074-8130-224920d8f044",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a263c0-0f39-49ca-8bf4-2a50582daa49",
   "metadata": {},
   "source": [
    "[6 points] The implementation of Scikit-Learn’s IDF calculation differs from that of the “standard” calculation. What is the justification for this change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcce42f-1f2f-4642-a159-19b106a7b5fc",
   "metadata": {},
   "source": [
    "The difference between Scikit-Learn's IDF calculation and the standard calculation is that Scikit-Learn adds '1' to the numerator and denominator of the IDF. It does this to simulate one extra document being seen that contains every term in the collection exactly once, which prevents zero divisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654dad7-52ae-4ad3-bae4-1c0695081402",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ada730-0fc3-421e-84c0-15e11e5d4849",
   "metadata": {},
   "source": [
    "[25 points] Each president has a .tar.gz file containing his speeches. Write a procedure to calculate TF.IDF for any president’s speeches and print the top-15 most important words in their speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd056919-f4fc-4568-a720-ed163901ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import tarfile\n",
    "import gzip\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c636dfb1-1df5-48cb-85dc-cbe16fdb6fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hannahmarr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7641daf-8b00-4029-8221-7e62a9bb541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf(president_tar_gz):\n",
    "  # Create a list to hold the speeches\n",
    "  speeches = []\n",
    "\n",
    "  # Open the .tar.gz file\n",
    "  with tarfile.open(president_tar_gz, 'r:gz') as tar:\n",
    "    # Iterate through each member in the tar file\n",
    "    for member in tar.getmembers():\n",
    "      # Check if the member is a file\n",
    "      if member.isfile():\n",
    "        # Extract and read the file\n",
    "        f = tar.extractfile(member)\n",
    "        if f is not None:\n",
    "          # Read the content and decode it\n",
    "          speeches.append(f.read().decode('utf-8'))\n",
    "\n",
    "  # Create a TF-IDF Vectorizer\n",
    "  vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "  # Fit and transform the speeches to get the TF-IDF matrix\n",
    "  tfidf_matrix = vectorizer.fit_transform(speeches)\n",
    "\n",
    "  # Get the feature names (words)\n",
    "  feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "  # Calculate the average TF-IDF score for each word\n",
    "  avg_tfidf_scores = tfidf_matrix.mean(axis=0).A1\n",
    "\n",
    "  # Create a dictionary to hold words and their scores\n",
    "  word_scores = defaultdict(float)\n",
    "\n",
    "  # Iterate through each word and its corresponding average TF-IDF score\n",
    "  for word, score in zip(feature_names, avg_tfidf_scores):\n",
    "    # Store the word and its score in the word_scores dictionary\n",
    "    word_scores[word] = score\n",
    "\n",
    "  # Sort words by TF-IDF score in descending order and get the top 15\n",
    "  top_words = sorted(word_scores.items(), key=lambda item: item[1], reverse=True)[:15]\n",
    "\n",
    "  # Print the top 15 words and their TF-IDF scores\n",
    "  print(\"Top 15 important words and their TF-IDF scores:\")\n",
    "  for word, score in top_words:\n",
    "    print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04df4387-a08c-472e-be8b-c9a946a7bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 important words and their TF-IDF scores:\n",
      "war: 0.0937\n",
      "people: 0.0842\n",
      "government: 0.0719\n",
      "world: 0.0669\n",
      "american: 0.0584\n",
      "peace: 0.0547\n",
      "united: 0.0538\n",
      "nation: 0.0536\n",
      "states: 0.0471\n",
      "men: 0.0468\n",
      "great: 0.0425\n",
      "nations: 0.0417\n",
      "new: 0.0407\n",
      "congress: 0.0396\n",
      "time: 0.0380\n"
     ]
    }
   ],
   "source": [
    "# Example usage: read fdroosevelt speeches\n",
    "calculate_tf_idf('/Users/hannahmarr/Desktop/Tufts/CS119/Quizzes/prez_speeches/fdroosevelt.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab5358d7-4794-4e46-85a4-a49b00ed308e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 important words and their TF-IDF scores:\n",
      "applause: 0.0942\n",
      "america: 0.0882\n",
      "iraq: 0.0852\n",
      "people: 0.0772\n",
      "world: 0.0626\n",
      "new: 0.0521\n",
      "country: 0.0515\n",
      "freedom: 0.0514\n",
      "nation: 0.0477\n",
      "iraqi: 0.0464\n",
      "security: 0.0464\n",
      "american: 0.0441\n",
      "terrorists: 0.0403\n",
      "help: 0.0401\n",
      "war: 0.0401\n"
     ]
    }
   ],
   "source": [
    "# Example usage: read bush speeches\n",
    "calculate_tf_idf('/Users/hannahmarr/Desktop/Tufts/CS119/Quizzes/prez_speeches/gwbush.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990f0da-fc02-44f4-b2f2-76895986da98",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc61f41-27c0-485d-8d1d-566725f33ca2",
   "metadata": {},
   "source": [
    "[15 points] Examine the result carefully – at least some of the top TF.IDF words should be historically consistent with what was going on in the country at the time. You only have a slight control over the outcome through starting with an initial set of stopwords and adding more words to the list of stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c683736-3148-4895-8cf4-ace3ba004b2d",
   "metadata": {},
   "source": [
    "The top 15 important words in FDR's speeches make sense in the context of the time. It was during FDR's presidency that World War II began, on September 1 of 1939. Thus, it makes sense that we see the word 'war' having the highest frequency. It was also during FDR's presidency that peace accords were drawn up following the end of WWII, so we would expect to see a high frequency of the word 'peace'. Additionally, plans for the United Nations were in the works, so it makes sense that we see both the words 'united' and 'nation' having a high frequency.\n",
    "\n",
    "The top 15 important words in George W. Bush's speeches also make sense in the context of the time. 9/11 was the defining event of his presidency, and shaped the subsequent Afghanistan war and rumors of weapons of mass destruction in Iraq. Thus, it very much makes sense that 'iraq', 'america', 'war', and 'terrorists' occur at a high frequency, since these words directly relate to 9/11 and ensuing events. Additionally, Bush presided over the formation of the Department of Homeland Security following 9/11; this is likely why we see the word 'security' occurring at a high frequency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
