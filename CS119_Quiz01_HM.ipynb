{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab31f330-21f8-4d2b-a446-f8bae36a9cf8",
   "metadata": {},
   "source": [
    "# Quiz 01: Beautiful Soup\n",
    "\n",
    "Primary Author: Hannah Marr\n",
    "\n",
    "Collaborator: Emma Virnelli\n",
    "\n",
    "CS 119\n",
    "\n",
    "9/19/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1ba71-26fd-48b2-8bc9-186032a0abae",
   "metadata": {},
   "source": [
    "Programmatic Extraction\n",
    "\n",
    "Reminder: Use “View Page Source” of the web page to view HTML of the page. Use “Inspect” to understand the HTML under a particular tag. If possible, please use Google Colab (or another Jupyter environment) as your programming environment as it allows for mixing code and text in the same file. Use a relatively recent version of Beautiful Soup with either \"html.parser\" or \"lxml\" parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa8893-b18b-4635-841e-7b135c04e2ca",
   "metadata": {},
   "source": [
    "Write a Python program books() to return the names of the canon books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd507a9-1e1d-478c-978f-4a0b4a0766b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #to use the Beautiful Soup package, we must import the library\n",
    "import requests #requests is a Python library that allows us to send HTTP requests very easily, and will allow us handle the URLs used here without manually adding query strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ffb31d-9a64-481b-a30d-aa17977f913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Alice's Adventures in Wonderland\", 'Through the Looking-Glass, and What Alice Found There', \"Alice's Adventures Underground\"]\n"
     ]
    }
   ],
   "source": [
    "def books():\n",
    "  #This will fetch the webpage content using the requests library\n",
    "  url = 'https://aliceinwonderland.fandom.com/wiki/Alice_in_Wonderland_Wiki'\n",
    "  response = requests.get(url)\n",
    "\n",
    "  #We then need to parse the webpage content using Beautiful Soup\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  #Next, from looking at the HTML of the webpage, and finding the <span> tag that contains the 'canon books' text, we learn that this HTML falls under a <ul> tag within the class 'wds-list wds-is-linked', and we need to get the <ul> element\n",
    "  canon_books_section = soup.find('span', string='Canon books')\n",
    "  if canon_books_section:\n",
    "    books_list = canon_books_section.find_next('ul', {'class': 'wds-list wds-is-linked'})\n",
    "\n",
    "    #Further, we see that each individual canon book is located within an <li> tag within this section, so to retrieve the titles of the canon books, we will need to fetch the text within each <li> tag\n",
    "    canon_books = books_list.find_all('li')\n",
    "\n",
    "    #Here, we extract and print the book titles as a list\n",
    "    book_titles = [book.find('span').get_text() for book in canon_books]\n",
    "    return book_titles\n",
    "  else:\n",
    "    return \"Canon books section not found.\"\n",
    "\n",
    "#Here we call the function and print the result\n",
    "print(books())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0d8ba-ba92-4230-b2f9-3d0502408714",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52428b-5361-406f-b850-0907a4c268b0",
   "metadata": {},
   "source": [
    "Write a Python program poems() to return the names of the canon poems and their URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1cadd48-fb89-4faa-ae54-22304d0d00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #to use the Beautiful Soup package, we must import the library\n",
    "import requests #requests is a Python library that allows us to send HTTP requests very easily, and will allow us handle the URLs used here without manually adding query strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dba5da20-016c-4193-85e2-d1544309bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jabberwocky: https://aliceinwonderland.fandom.com/wiki/Jabberwocky\n",
      "How Doth the Little Crocodile: https://aliceinwonderland.fandom.com/wiki/How_Doth_the_Little_Crocodile\n",
      "The Walrus and the Carpenter: https://aliceinwonderland.fandom.com/wiki/The_Walrus_and_the_Carpenter_(poem)\n",
      "You Are Old, Father William: https://aliceinwonderland.fandom.com/wiki/You_Are_Old,_Father_William\n",
      "Humpty Dumpty's Recitation: https://aliceinwonderland.fandom.com/wiki/Humpty_Dumpty%27s_Recitation\n",
      "Turtle Soup: https://aliceinwonderland.fandom.com/wiki/Turtle_Soup\n",
      "Tis the Voice of the Lobster: https://aliceinwonderland.fandom.com/wiki/Tis_the_Voice_of_the_Lobster\n"
     ]
    }
   ],
   "source": [
    "def poems():\n",
    "  #This will fetch the webpage content using the requests library\n",
    "  url = 'https://aliceinwonderland.fandom.com/wiki/Alice_in_Wonderland_Wiki'\n",
    "  response = requests.get(url)\n",
    "\n",
    "  #We then need to parse the webpage content using Beautiful Soup\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  #Now we will locate the <span> tag with the text 'canon poems' and fetch the following <ul> element\n",
    "  canon_poems_section = soup.find('span', string='Canon poems')\n",
    "  if canon_poems_section:\n",
    "    poems_list = canon_poems_section.find_next('ul', {'class': 'wds-list wds-is-linked'})\n",
    "\n",
    "    #Now we will extract all the <li> tags within this section\n",
    "    canon_poems = poems_list.find_all('li')\n",
    "\n",
    "    #Here we extract the poem names and URLs and append to the poems_data list\n",
    "    poems_data = []\n",
    "    for poem in canon_poems:\n",
    "      poem_name = poem.find('span').get_text()  #This retrieves the poem title\n",
    "      poem_url = poem.find('a')['href']  #This retrieves the poem URL\n",
    "      poems_data.append({'name': poem_name, 'url': poem_url}) #This appends the data we've extracted to the poems_data list\n",
    "    return poems_data\n",
    "  else:\n",
    "    return \"Canon poems section not found.\"\n",
    "\n",
    "#Now we call the function and print the result\n",
    "poems_list = poems()\n",
    "for poem in poems_list:\n",
    "  print(f\"{poem['name']}: {poem['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72ae88-9000-429e-8426-3c37fdca0214",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538369d-c8ba-4f18-8c94-c087d062bb4e",
   "metadata": {},
   "source": [
    "Write a Python program poem_title_text(n) that calls poems() and, using n as the index and returns the poem title and its text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af02461f-30d5-4558-b381-dcd5fc6687ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Walrus and the Carpenter\n",
      "\n",
      "Text:\n",
      "\n",
      "\n",
      "\n",
      "Illustration by Sir John Tenniel.\n",
      "\n",
      "The Walrus and the Carpenter is a poem by Lewis Carroll that appears within his 1871 novel, Through the Looking-Glass, and What Alice Found There. Tweedledee and Tweedledum perform it for Alice in the fourth chapter.\n",
      "\n",
      "\n",
      "The sun was shining on the sea,\n",
      "Shining with all his might:\n",
      "He did his very best to make\n",
      "The billows smooth and bright--\n",
      "And this was odd, because it was\n",
      "The middle of the night.\n",
      "\n",
      "\n",
      "The moon was shining sulkily,\n",
      "Because she thought the sun\n",
      "Had got no business to be there\n",
      "After the day was done--\n",
      "\"It's very rude of him,\" she said,\n",
      "\"To come and spoil the fun!\"\n",
      "\n",
      "\n",
      "The sea was wet as wet could be,\n",
      "The sands were dry as dry.\n",
      "You could not see a cloud, because\n",
      "No cloud was in the sky:\n",
      "No birds were flying overhead--\n",
      "There were no birds to fly.\n",
      "\n",
      "\n",
      "The Walrus and the Carpenter\n",
      "Were walking close at hand;\n",
      "They wept like anything to see\n",
      "Such quantities of sand:\n",
      "\"If this were only cleared away,\"\n",
      "They said, \"it would be grand!\"\n",
      "\n",
      "\n",
      "\"If seven maids with seven mops\n",
      "Swept it for half a year.\n",
      "Do you suppose,\" the Walrus said,\n",
      "\"That they could get it clear?\"\n",
      "\"I doubt it,\" said the Carpenter,\n",
      "And shed a bitter tear.\n",
      "\n",
      "\n",
      "\"O Oysters, come and walk with us!\"\n",
      "The Walrus did beseech.\n",
      "\"A pleasant walk, a pleasant talk,\n",
      "Along the briny beach:\n",
      "We cannot do with more than four,\n",
      "To give a hand to each.\"\n",
      "\n",
      "\n",
      "The eldest Oyster looked at him,\n",
      "But never a word he said:\n",
      "The eldest Oyster winked his eye,\n",
      "And shook his heavy head--\n",
      "Meaning to say he did not choose\n",
      "To leave the oyster-bed.\n",
      "\n",
      "\n",
      "But four young Oysters hurried up,\n",
      "All eager for the treat:\n",
      "Their coats were brushed, their faces washed,\n",
      "Their shoes were clean and neat--\n",
      "And this was odd, because, you know,\n",
      "They hadn't any feet.\n",
      "\n",
      "\n",
      "Four other Oysters followed them,\n",
      "And yet another four;\n",
      "And thick and fast they came at last,\n",
      "And more, and more, and more--\n",
      "All hopping through the frothy waves,\n",
      "And scrambling to the shore.\n",
      "\n",
      "\n",
      "The Walrus and the Carpenter\n",
      "Walked on a mile or so,\n",
      "And then they rested on a rock\n",
      "Conveniently low:\n",
      "And all the little Oysters stood\n",
      "And waited in a row.\n",
      "\n",
      "\n",
      "\"The time has come,\" the Walrus said,\n",
      "\"To talk of many things:\n",
      "Of shoes--and ships--and sealing-wax--\n",
      "Of cabbages--and kings--\n",
      "And why the sea is boiling hot--\n",
      "And whether pigs have wings.\"\n",
      "\n",
      "\n",
      "\"But wait a bit,\" the Oysters cried,\n",
      "\"Before we have our chat;\n",
      "For some of us are out of breath,\n",
      "And all of us are fat!\"\n",
      "\"No hurry!\" said the Carpenter.\n",
      "They thanked him much for that.\n",
      "\n",
      "\n",
      "\"A loaf of bread,\" the Walrus said,\n",
      "\"Is what we chiefly need:\n",
      "Pepper and vinegar besides\n",
      "Are very good indeed--\n",
      "Now if you're ready, Oysters dear,\n",
      "We can begin to feed.\"\n",
      "\n",
      "\n",
      "\"But not on us!\" the Oysters cried,\n",
      "Turning a little blue.\n",
      "\"After such kindness, that would be\n",
      "A dismal thing to do!\"\n",
      "\"The night is fine,\" the Walrus said.\n",
      "\"Do you admire the view?\n",
      "\n",
      "\n",
      "\"It was so kind of you to come!\n",
      "And you are very nice!\"\n",
      "The Carpenter said nothing but\n",
      "\"Cut us another slice:\n",
      "I wish you were not quite so deaf--\n",
      "I've had to ask you twice!\"\n",
      "\n",
      "\n",
      "\"It seems a shame,\" the Walrus said,\n",
      "\"To play them such a trick,\n",
      "After we've brought them out so far,\n",
      "And made them trot so quick!\"\n",
      "The Carpenter said nothing but\n",
      "\"The butter's spread too thick!\"\n",
      "\n",
      "\n",
      "\"I weep for you,\" the Walrus said:\n",
      "\"I deeply sympathize.\"\n",
      "With sobs and tears he sorted out\n",
      "Those of the largest size,\n",
      "Holding his pocket-handkerchief\n",
      "Before his streaming eyes.\n",
      "\n",
      "\n",
      "\"O Oysters,\" said the Carpenter,\n",
      "\"You've had a pleasant run!\n",
      "Shall we be trotting home again?'\n",
      "But answer came there none--\n",
      "And this was scarcely odd, because\n",
      "They'd eaten every one.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#We can reuse the poems function for this\n",
    "def poems():\n",
    "  url = 'https://aliceinwonderland.fandom.com/wiki/Alice_in_Wonderland_Wiki'\n",
    "  response = requests.get(url)\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  canon_poems_section = soup.find('span', string='Canon poems')\n",
    "  if canon_poems_section:\n",
    "    poems_list = canon_poems_section.find_next('ul', {'class': 'wds-list wds-is-linked'})\n",
    "    canon_poems = poems_list.find_all('li')\n",
    "\n",
    "    poems_data = []\n",
    "    for poem in canon_poems:\n",
    "      poem_name = poem.find('span').get_text()  #This retrieves the poem title\n",
    "      poem_url = poem.find('a')['href']  #This retrieves the poem URL\n",
    "      #This constructs a full URL if it is not given\n",
    "      if not poem_url.startswith('http'):\n",
    "        poem_url = 'https://aliceinwonderland.fandom.com' + poem_url\n",
    "      poems_data.append({'name': poem_name, 'url': poem_url})\n",
    "\n",
    "    return poems_data\n",
    "  else:\n",
    "    return []\n",
    "\n",
    "#Now we create the new poem_title_text function\n",
    "def poem_title_text(n):\n",
    "  all_poems = poems()  #This fetches all poems and their URLs\n",
    "\n",
    "  #Here we check if the index n is valid\n",
    "  if n < 0 or n >= len(all_poems):\n",
    "    return f\"No poem at index {n}. Available range is from 0 to {len(all_poems) - 1}.\"\n",
    "\n",
    "  #This retrieves the poem's title and URL based on the index n\n",
    "  poem_title = all_poems[n]['name']\n",
    "  poem_url = all_poems[n]['url']\n",
    "\n",
    "  #Now we fetch the poem page content\n",
    "  poem_page = requests.get(poem_url)\n",
    "  poem_soup = BeautifulSoup(poem_page.text, 'html.parser')\n",
    "\n",
    "  #Here, from examining the HTML view of the page, we know we must extract the poem text from the <div class=\"mw-parser-output\">\n",
    "  poem_text_section = poem_soup.find('div', {'class': 'mw-parser-output'})\n",
    "\n",
    "  if poem_text_section:\n",
    "    #Now we must extract individual paragraphs within the maw-parser-output section\n",
    "    poem_text_parts = poem_text_section.find_all('p')\n",
    "\n",
    "    #Since the text may be in multiple paragraphs, here we join the text of all the paragraphs\n",
    "    poem_text = '\\n\\n'.join([p.get_text() for p in poem_text_parts])\n",
    "  else:\n",
    "    poem_text = \"Poem text not found.\"\n",
    "\n",
    "  #This code returns the poem title and text\n",
    "  return {'title': poem_title, 'text': poem_text}\n",
    "\n",
    "#For example, here is how we would retrieve the title and text of the poem at index 2\n",
    "poem_data = poem_title_text(2)\n",
    "print(f\"Title: {poem_data['title']}\\n\\nText:\\n{poem_data['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9ae58c-9ae7-49f1-85f1-c9dc62719ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Turtle Soup\n",
      "\n",
      "Text:\n",
      "\"Turtle Soup\" is a song sung by the Mock Turtle in Chapter 10 of Alice's Adventures in Wonderland. It is a parody of the poem \"Star of the Evening.\"\n",
      "\n",
      "\n",
      "Beautiful Soup, so rich and green,\n",
      "Waiting in a hot tureen!\n",
      "Who for such dainties would not stoop?\n",
      "Soup of the evening, beautiful Soup!\n",
      "Soup of the evening, beautiful Soup!\n",
      "\n",
      "\n",
      "Beau--ootiful Soo--oop!\n",
      "Beau--ootiful Soo--oop!\n",
      "Soo--oop of the e--e--evening,\n",
      "Beautiful, beautiful Soup!\n",
      "\n",
      "\n",
      "Beautiful Soup! Who cares for fish,\n",
      "Game or any other dish?\n",
      "Who would not give all else for two\n",
      "Pennyworth only of Beautiful Soup?\n",
      "Pennyworth only of beautiful Soup?\n",
      "\n",
      "\n",
      "Beau--ootiful Soo--oop!\n",
      "Beau--ootiful Soo--oop!\n",
      "Soo--oop of the e--e--evening,\n",
      "Beautiful, beauti--FUL SOUP!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#As another example, here is how we would retrieve the title and text of the poem at index 5\n",
    "poem_data = poem_title_text(5)\n",
    "print(f\"Title: {poem_data['title']}\\n\\nText:\\n{poem_data['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4aca92-ff31-41b9-9582-8d1c1739d9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
